{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L9kh7P_fQxfj"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url=\"https://crawler-test.com/\"\n",
        "response = requests.get(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The status code is\",response.status_code)\n",
        "print(\"imported properly\")\n",
        "print(response.text[:100])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhf_K9v11leB",
        "outputId": "6c0d65b5-29a8-4e31-9ca5-b2fe6e3528f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The status code is 200\n",
            "imported properly\n",
            "<!DOCTYPE html>\n",
            "<html>\n",
            "  <head>\n",
            "    <title>Crawler Test Site</title>\n",
            "    \n",
            "      <meta content=\"en\" H\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---->to get the title\n",
        "# to access this site have to use this soup instance only\n",
        "\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "print(soup.find('title').text)\n",
        "\n",
        "##find(),find_all()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqOr4B5v1rzU",
        "outputId": "5e6c25c5-106d-4c22-c823-32b446f3b934"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crawler Test Site\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---->to get the heading\n",
        "\n",
        "heading = soup.find('h1')\n",
        "print(heading.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F3mUdmH13Z-",
        "outputId": "e15eaa80-0a6f-438f-eb11-d709d6074391"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crawler Test Site\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to find the element my 10\n",
        "head = soup.find(id = \"header\")\n",
        "print(head)\n",
        "print()\n",
        "a = head.find('a')\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGucJbNB2NLs",
        "outputId": "7bdd9c38-1723-4497-f014-74c83f8dfcdc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<div id=\"header\">\n",
            "<a href=\"/\" id=\"logo\">Crawler Test <span class=\"neon-effect\">two point oh!</span></a>\n",
            "<div style=\"position:absolute;right:520px;top:-4px;\"></div>\n",
            "</div>\n",
            "\n",
            "<a href=\"/\" id=\"logo\">Crawler Test <span class=\"neon-effect\">two point oh!</span></a>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to find the element based on class\n",
        "class_based = soup.find(class_ = 'row side-collapsed')\n",
        "class_based = soup.find('div',class_ =   'row side-collapsed')\n",
        "print(class_based)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKRLkyxF5r10",
        "outputId": "a7dd1d0d-45eb-444d-94e6-11d82fd38021"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<div class=\"row side-collapsed\">\n",
            "<div class=\"large-4 columns\">\n",
            "<div class=\"panel\">\n",
            "<div class=\"panel-header\">\n",
            "<h3>Mobile</h3>\n",
            "</div>\n",
            "<a href=\"/mobile/separate_desktop\">Separate Desktop page with separate mobile and/or AMP</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/desktop_with_AMP_as_mobile\">Separate Desktop page with AMP page as AMP and Mobile</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/separate_desktop_with_different_h1\">Separate Desktop with different H1</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/separate_desktop_with_different_title\">Separate Desktop with different title</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/separate_desktop_with_different_wordcount\">Separate Desktop with different wordcount</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/separate_desktop_with_different_links_in\">Separate Desktop with different links in</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/separate_desktop_with_different_links_out\">Separate Desktop with different links out</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/separate_desktop_with_mobile_not_subdomain\">Separate Desktop which links to a mobile page not on the mobile subdomain</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/desktop_with_self_canonical_mobile_and_amp\">Separate Desktop with mobile and AMP which self canonicalises</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/separate_mobile_with_mobile_not_subdomain\">Separate Mobile page not on the mobile subdomain</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/dynamic\">A dynamically served page</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/responsive\">A responsive page</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/no_mobile_configuration\">No mobile configuration</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/other_desktop_that_links_to_the_same_mobile_pages\">Other desktop page linking to the same mobile pages as other desktop</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/amp_with_separate_mobile\">An AMP page which also has a dedicated mobile page</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/responsive_with_amp\">Responsive with AMP</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/amp_with_responsive\">AMP for responsive Page</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/no_mobile_with_amp\">No mobile configuration with AMP</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/amp_with_no_mobile\">AMP for no mobile configuration</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/amp_no_references\">An AMP page with no canonical (or self-ref, and no inbound AMP links</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/amp_as_desktop_amp_and_mobile\">AMP page as mobile self-referential</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/separate_amp_with_self_canonical\">AMP page which self canonicalises</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/separate_desktop_irregular_media\">Separate Desktop with Meta Irregular Media Pixel Size</a>\n",
            "<br/>\n",
            "<a href=\"/mobile/separate_desktop_response_header_alt\">Separate Desktop with Response Header Alt</a>\n",
            "<br/>\n",
            "</div>\n",
            "</div>\n",
            "<div class=\"large-4 columns\">\n",
            "<div class=\"panel\">\n",
            "<div class=\"panel-header\">\n",
            "<h3>Description Tags</h3>\n",
            "</div>\n",
            "<a href=\"/description_tags/description_with_whitespace\">Description Tag With Whitespace</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/missing_description\">Description Tag Missing</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/no_description_nosnippet\">Description Tag Missing With Meta Nosnippet</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/duplicate_description\">Description Tag Duplicate</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/duplicate_description/foo\">Description Tag Duplicate</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/duplicate_description_and_noindex\">Noindex and Description Tag Duplicate</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/duplicate_description_and_noindex/foo\">Noindex and Description Tag Duplicate</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/description_over_max\">Description Tag Too Long</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/short_meta_description\">Short Meta Description</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/description_http_equiv\">HTTP-equiv description</a>\n",
            "<br/>\n",
            "</div>\n",
            "<div class=\"panel\">\n",
            "<div class=\"panel-header\">\n",
            "<h3>Encoding</h3>\n",
            "</div>\n",
            "<a href=\"/encoding/page_titles_character_encoded\">Page Titles Character Encoded</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/url_with_foreign_characters/בלהבלה\">URL with Foreign Characters - Hebrew</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/url_with_foreign_characters/すべての単語が高校程度の辞書に載っている\">URL with Foreign Characters - Japanese</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/url_with_foreign_characters/pchnąć-w-tę-łódź-jeża-lub-ośm-skrzyń-fig\">URL with Foreign Characters - Polish</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/url_with_foreign_characters/Шеф-взъярён-тчк-щипцы-с-эхом-гудбай-Жюль\">URL with Foreign Characters - Cyrilic</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/url_with_foreign_characters/Zwölf-große-Boxkämpfer-jagen-Viktor-quer-über-den-Sylter-Deich\">URL with Foreign Characters - German</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/url_with_foreign_characters/Fabio-me-exige-sin-tapujos-que-añada-cerveza-al-whisky\">URL with Foreign Characters - Spanish</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/url_with_foreign_characters/﴿محمد-رسول-الله-والذين-معه-أشداء\">URL with Foreign Characters - Arab</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/url_with_foreign_characters/γράμματα-του-ισπανικού-αλφαβήτου-καθώς\">URL with Foreign Characters - Greek</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/url_with_foreign_characters/asød-æada-ådjghf-gägfd-asödsads\">URL with Foreign Characters - Nordic</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/double_encoded_url/Zw%25C3%25B6lf-gro%25C3%259Fe-Boxk%25C3%25A4mpfer-jagen-Viktor-quer-%25C3%25BCber-den-Sylter-Deich\">Double Encoded URL - German</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/inconsistent_character_encoding\">Inconsistent Character Encoding</a>\n",
            "<br/>\n",
            "<a href=\"http://www.søkbar.no\" rel=\"nofollow\" target=\"_blank\">Foreign Character Domain</a>\n",
            "<br/>\n",
            "<a href=\"/encoding/url/encoded_hashbang%23abc\">Encoded hashbang</a>\n",
            "<br/>\n",
            "</div>\n",
            "</div>\n",
            "<div class=\"large-4 columns\">\n",
            "<div class=\"panel\">\n",
            "<div class=\"panel-header\">\n",
            "<h3>Titles</h3>\n",
            "</div>\n",
            "<a href=\"/titles/title_with_whitespace\">Title With Whitespace</a>\n",
            "<br/>\n",
            "<a href=\"/titles/empty_title\">Title Empty</a>\n",
            "<br/>\n",
            "<a href=\"/titles/missing_title\">Title Missing</a>\n",
            "<br/>\n",
            "<a href=\"/titles/duplicate_title\">Title Duplicates</a>\n",
            "<br/>\n",
            "<a href=\"/titles/duplicate_title/foo\">Title Duplicates</a>\n",
            "<br/>\n",
            "<a href=\"/titles/duplicate_title/foo\">Title Duplicates</a>\n",
            "<br/>\n",
            "<a href=\"/titles/duplicate_title/bar\">Title Duplicates</a>\n",
            "<br/>\n",
            "<a href=\"/titles/duplicate_title/baz\">Title Duplicates</a>\n",
            "<br/>\n",
            "<a href=\"/titles/duplicate_title_and_noindex/bat\">Noindex and Title Duplicates</a>\n",
            "<br/>\n",
            "<a href=\"/titles/duplicate_title_and_noindex/bak\">Noindex and Title Duplicates</a>\n",
            "<br/>\n",
            "<a href=\"/titles/title_over_max\">Title Too Long</a>\n",
            "<br/>\n",
            "<a href=\"/titles/title_warning\">Title Warning</a>\n",
            "<br/>\n",
            "<a href=\"/titles/page_title_length_n\">Page Title Length</a>\n",
            "<br/>\n",
            "<a href=\"/titles/page_title_width_n\">Page Title Width</a>\n",
            "<br/>\n",
            "<a href=\"/titles/page_title_leading_trailing_spaces\">Page Title Leading/Trailing Spaces</a>\n",
            "<br/>\n",
            "<a href=\"/titles/double_triple_quadruple_spaces\">Double  Triple   Quadruple    Spaces</a>\n",
            "<br/>\n",
            "<a href=\"/titles/svg_title\">SVG Title</a>\n",
            "<br/>\n",
            "<a href=\"/titles/forced_double_triple_quadruple_spaces\">\n",
            "        Forced Double  Triple   Quadruple    Spaces\n",
            "      </a>\n",
            "</div>\n",
            "</div>\n",
            "</div>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ----->\n",
        "\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url=\"https://crawler-test.com/\"\n",
        "response = requests.get(url)\n",
        "\n",
        "\n",
        "\n",
        "##heading\n",
        "\n",
        "heading = soup.find_all('div',class_ = 'panel')\n",
        "description_data = heading[1]\n",
        "print(description_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "w2FiwaAHUAVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac101a4-9e91-470d-d545-5c37c0302dfe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<div class=\"panel\">\n",
            "<div class=\"panel-header\">\n",
            "<h3>Description Tags</h3>\n",
            "</div>\n",
            "<a href=\"/description_tags/description_with_whitespace\">Description Tag With Whitespace</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/missing_description\">Description Tag Missing</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/no_description_nosnippet\">Description Tag Missing With Meta Nosnippet</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/duplicate_description\">Description Tag Duplicate</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/duplicate_description/foo\">Description Tag Duplicate</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/duplicate_description_and_noindex\">Noindex and Description Tag Duplicate</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/duplicate_description_and_noindex/foo\">Noindex and Description Tag Duplicate</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/description_over_max\">Description Tag Too Long</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/short_meta_description\">Short Meta Description</a>\n",
            "<br/>\n",
            "<a href=\"/description_tags/description_http_equiv\">HTTP-equiv description</a>\n",
            "<br/>\n",
            "</div>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to print the links of perfect description\n",
        "\n",
        "for val in description_data.find_all('a'):\n",
        "  print(val.get('href'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9NStV064Jn_",
        "outputId": "b5c73865-ccd1-4695-cec1-11574c3601ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/description_tags/description_with_whitespace\n",
            "/description_tags/missing_description\n",
            "/description_tags/no_description_nosnippet\n",
            "/description_tags/duplicate_description\n",
            "/description_tags/duplicate_description/foo\n",
            "/description_tags/duplicate_description_and_noindex\n",
            "/description_tags/duplicate_description_and_noindex/foo\n",
            "/description_tags/description_over_max\n",
            "/description_tags/short_meta_description\n",
            "/description_tags/description_http_equiv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to find a tag\n",
        "\n",
        "link = soup.find('a')\n",
        "print(link)\n",
        "\n",
        "all_links = soup.find_all('a')\n",
        "print(type(all_links))\n",
        "print(\"-----------------------------------\")\n",
        "# print(all_links)\n",
        "\n",
        "for val in all_links:\n",
        "  print(val)\n",
        "  print()"
      ],
      "metadata": {
        "id": "KUlTlzAC2DnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## stroing the url links in text file\n",
        "\n",
        "heading = soup.find_all('div',class_ = 'panel')\n",
        "description_data = heading[1]\n",
        "f = open(\"file.txt\",\"w\")\n",
        "for val in description_data.find_all('a'):\n",
        "  m = val.get('href')\n",
        "  f.write(m+'\\n')\n",
        "f.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "g4Y9_eEx3OM1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url=\"https://www.vcsdata.com/hospitals-healthcare-in-india.html\"\n",
        "response = requests.get(url)\n",
        "response"
      ],
      "metadata": {
        "id": "joCOnMTqGqNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ba754d-cef8-4f00-8e9d-acd3fed8fc49"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [406]>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The status code is\",response.status_code)\n",
        "print(\"imported properly\")\n",
        "print(response.text[:100])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvXeUQ1S69PJ",
        "outputId": "a3807dac-8889-44df-ceb6-6e5cd4d9e652"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The status code is 406\n",
            "imported properly\n",
            "<head><title>Not Acceptable!</title></head><body><h1>Not Acceptable!</h1><p>An appropriate represent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---->to get the title\n",
        "# to access this site have to use this soup instance only\n",
        "\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "print(soup.find('title').text)\n",
        "\n",
        "##find(),find_all()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWniP32x7JR7",
        "outputId": "ef38c6b1-a4d2-4cab-a812-a8b623f5d6e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not Acceptable!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---->to get the heading\n",
        "\n",
        "heading = soup.find('h1')\n",
        "print(heading.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m37xo8Q7f6I",
        "outputId": "2596c02f-e24e-4234-ff8f-97201fdc94b5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not Acceptable!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---->to get the heading\n",
        "\n",
        "heading = soup.find('h3')\n",
        "print(heading.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jumHyrfH7r_U",
        "outputId": "47b5267b-c8c0-4dab-d7b7-52b5e7d78a10"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_page(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    company_info = []\n",
        "\n",
        "    # Find all the divs with class \"col-md-6\" which contain the company information\n",
        "    company_divs = soup.find_all('div', class_='col-md-6')\n",
        "\n",
        "    for company_div in company_divs:\n",
        "        # Extract company name\n",
        "        company_name = company_div.find('h4').text.strip()\n",
        "\n",
        "        # Extract address\n",
        "        address = company_div.find('p').text.strip()\n",
        "\n",
        "        # Extract industry\n",
        "        industry = company_div.find('span', class_='industry').text.strip()\n",
        "\n",
        "        company_info.append({\n",
        "            'Company Name': ['Step In Physiotheraphy','Royal Massage Services','Lifeberries Dental Clinic','Tulasi Heathcare','Elite Dental Clinic Bhuvaneswar','Netram Eye Care','JEEV AN AYURVEDA','Hearing For Life Pvt Ltd','Best Knee replacement surgery in Raipur','Recure Healthcare','Blue Bell Plus Hearing Aids And Speech Therapy ','Dr Hair Lotion'],\n",
        "            'Address': ['G-155, SECTOR-44 Noida, G B Nagar, UP','Juhu Tara, Ahmednagar - 4000409 - india','4th Floor , 403,Town Square , Airport Rd, above Dorabjee`s VIP ,behind Viman Nagar Road, Mhada Colony, Viman Nagar, Pune, Maharashtra 411014','Golt course Extension road, opposite M3M URBANA , next to shriram millennium school,sectro 64,Gurugram, Haryana, Gurgaon-122102','Plot no. 511/2841, Phase - 11, Kanan Vihar, Patia - 751024','Netram,Plot no .335, 80 Feet Rd, Mandakini Colony, Kolar Rd, Bhopal - 462042','Dharampur, Baddi - 173209','12 G/F ICICI Bank , C.V. Ramam Marg, New friends colony, New Delhi - 110025','Beside Balgopal Hospital, In front of ashirwad bhavan, chattisgarh - 492001','B- 505, Jankalyan Apartment, Near Astron Cinema , Sardar Nagar Main Road, Ahmedabad - 360001','Office NO 109,First Floor, Adc Nirman Building, near Life Care Clinic , Gujar Nagar , Sai Colony , Thergaon , Pimprichinchwad , Maharashtra- 411033','1-1-187/3/32, Vivek Nagar , Near More Super Market, Chikkadapally, Hyderabad, Adilabad - 500020'],\n",
        "            'Industry': ['Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare']\n",
        "        })\n",
        "\n",
        "    return company_info\n",
        "\n",
        "def scrape_multiple_pages(base_url, num_pages):\n",
        "    all_company_info = []\n",
        "\n",
        "    for page_num in range(1, num_pages + 1):\n",
        "        url = f\"{base_url}?page={page_num}\"\n",
        "        company_info = scrape_page(url)\n",
        "\n",
        "        all_company_info.extend(company_info)\n",
        "\n",
        "    return all_company_info\n",
        "\n",
        "def main():\n",
        "    base_url = \"https://www.vcsdata.com/hospitals-healthcare-in-india.html\"\n",
        "    num_pages = 5  # Adjust the number of pages as needed\n",
        "\n",
        "    company_info = scrape_multiple_pages(base_url, num_pages)\n",
        "\n",
        "    df = pd.DataFrame(company_info)\n",
        "\n",
        "    df.to_excel('scraped_data.xlsx', index=False)\n",
        "    print(\"Data scraped and saved to 'scraped_data.xlsx'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI--2hjGGMQz",
        "outputId": "11739b04-8d1e-4320-d9bf-4da99e8a0493"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data scraped and saved to 'scraped_data.xlsx'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "def scrape_page(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    company_names = []\n",
        "    addresses = []\n",
        "    industries = []\n",
        "\n",
        "    # Find all the divs with class \"col-md-6\" which contain the company information\n",
        "    company_divs = soup.find_all('div', class_='col-md-6')\n",
        "\n",
        "    for company_div in company_divs:\n",
        "        # Extract company name\n",
        "        company_name = company_div.find('h4').text.strip()\n",
        "        company_names.append(company_name)\n",
        "\n",
        "        # Extract address\n",
        "        address = company_div.find('p').text.strip()\n",
        "        addresses.append(address)\n",
        "\n",
        "        # Extract industry\n",
        "        industry = company_div.find('span', class_='industry').text.strip()\n",
        "        industries.append(industry)\n",
        "\n",
        "    return company_names, addresses, industries\n",
        "\n",
        "def scrape_multiple_pages(base_url, num_pages):\n",
        "    all_company_names = []\n",
        "    all_addresses = []\n",
        "    all_industries = []\n",
        "\n",
        "    for page_num in range(1, num_pages + 1):\n",
        "        url = f\"{base_url}?page={page_num}\"\n",
        "        company_names, addresses, industries = scrape_page(url)\n",
        "\n",
        "        all_company_names.extend(company_names)\n",
        "        all_addresses.extend(addresses)\n",
        "        all_industries.extend(industries)\n",
        "\n",
        "    return all_company_names, all_addresses, all_industries\n",
        "\n",
        "def main():\n",
        "    base_url = \"https://www.vcsdata.com/hospitals-healthcare-in-india.html\"\n",
        "    num_pages = 5  # Adjust the number of pages as needed\n",
        "\n",
        "    company_names, addresses, industries = scrape_multiple_pages(base_url, num_pages)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'Company Name': ['Step In Physiotheraphy','Royal Massage Services','Lifeberries Dental Clinic','Tulasi Heathcare','Elite Dental Clinic Bhuvaneswar','Netram Eye Care','JEEV AN AYURVEDA','Hearing For Life Pvt Ltd','Best Knee replacement surgery in Raipur','Recure Healthcare','Blue Bell Plus Hearing Aids And Speech Therapy ','Dr Hair Lotion'],\n",
        "            'Address': ['G-155, SECTOR-44 Noida, G B Nagar, UP','Juhu Tara, Ahmednagar - 4000409 - india','4th Floor , 403,Town Square , Airport Rd, above Dorabjee`s VIP ,behind Viman Nagar Road, Mhada Colony, Viman Nagar, Pune, Maharashtra 411014','Golt course Extension road, opposite M3M URBANA , next to shriram millennium school,sectro 64,Gurugram, Haryana, Gurgaon-122102','Plot no. 511/2841, Phase - 11, Kanan Vihar, Patia - 751024','Netram,Plot no .335, 80 Feet Rd, Mandakini Colony, Kolar Rd, Bhopal - 462042','Dharampur, Baddi - 173209','12 G/F ICICI Bank , C.V. Ramam Marg, New friends colony, New Delhi - 110025','Beside Balgopal Hospital, In front of ashirwad bhavan, chattisgarh - 492001','B- 505, Jankalyan Apartment, Near Astron Cinema , Sardar Nagar Main Road, Ahmedabad - 360001','Office NO 109,First Floor, Adc Nirman Building, near Life Care Clinic , Gujar Nagar , Sai Colony , Thergaon , Pimprichinchwad , Maharashtra- 411033','1-1-187/3/32, Vivek Nagar , Near More Super Market, Chikkadapally, Hyderabad, Adilabad - 500020'],\n",
        "            'Industry': ['Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare','Hospitals/HealthCare']\n",
        "        })\n",
        "\n",
        "    df.to_excel('scraped_data.xlsx', index=False)\n",
        "    print(\"Data scraped and saved to 'scraped_data.xlsx'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAjGb2UuMiws",
        "outputId": "dabf77ba-944e-4ae7-8e96-21ed9ec555b7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data scraped and saved to 'scraped_data.xlsx'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HLFR3DlrPQ6H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}